{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, sys, multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from sqlalchemy import create_engine, MetaData, Table, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 1: Create the vocabulary.txt file'''\n",
    "\n",
    "def getMimicTexts():\n",
    "    '''\n",
    "    Input: N/A\n",
    "    Output: List[Strings] for all 2 million+ MIMIC texts **lowercase**. \n",
    "    We're going to use this List[Strings] to create the set of vocabulary words that is needed for BiLM.\n",
    "    '''\n",
    "    t1 = time.time() #start timer\n",
    "    \n",
    "    engine = create_engine('sqlite:///mimic.db') #initiated database engine\n",
    "    conn = engine.connect()\n",
    "    metadata = MetaData(bind=engine) #init metadata. will be empty\n",
    "    metadata.reflect(engine) #retrieve db info for metadata (tables, columns, types)\n",
    "    mydata = Table('mydata', metadata)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    #Query db for text. Not efficient. Soz bro.   \n",
    "    s = select([mydata.c.TEXT]) \n",
    "    print(type(s))\n",
    "    result = conn.execute(s)\n",
    "    print(type(result))\n",
    "    for row in result:\n",
    "        #text\n",
    "        the_text = row[\"TEXT\"]\n",
    "        keep_text = the_text.rstrip()\n",
    "        lower_text = keep_text.lower() #lowercase v important.\n",
    "        formatted_text = ' '.join(lower_text.split()) #make it all on one line...\n",
    "        '''TODO: honestly a bit more preprocessing could go here for trailing punctuation. \n",
    "        We'll have a problem with 'word.' versus 'word .' but i don't feel like fixing this right now...''' \n",
    "        data.append(lower_text)\n",
    "    \n",
    "    print(\" * Finished step0: done in %0.3fs.\" % (time.time() - t1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_docs = getMimicTexts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Example ##### \n",
    "print(\"* list_of_all_docs is a: \", type(list_of_all_docs))\n",
    "print(\"* documents in list_of_all_docs are: \", type(list_of_all_docs[0]))\n",
    "print(\"* Example documents: \", list_of_all_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSetOfWords(document):\n",
    "    '''\n",
    "    Input: String\n",
    "    Output: Set(Strings) = This will output the set of tokens in the document\n",
    "    TODO: What tokenizer do we want to use? I'm just gonna use white space here for now \n",
    "    because that's a problem for future-me.\n",
    "    '''\n",
    "    words_list: list[string] = document.split()\n",
    "    unique_words: set = set(words_list)\n",
    "    return unique_words\n",
    "\n",
    "unique_words_example = getSetOfWords(list_of_all_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create the vocab.txt that is necessary to run BiLM\n",
    "'''\n",
    "def createVocabFile():\n",
    "    '''\n",
    "    Input: String = Point it at the text file that contains all of the mimic files!\n",
    "    '''\n",
    "    t1 = time.time() #start the timer\n",
    "    \n",
    "    pool_size = multiprocessing.cpu_count() #Usin' all yer CPU's my friend. \n",
    "    pool = Pool(pool_size)\n",
    "    print('* created worker pools')\n",
    "    results0 = pool.map_async(getSetOfWords, list_of_all_docs[0:3])  #TODO: this will be the whole set, not a subset\n",
    "    print('* initialized map_async to naiveSearchText function with docs')\n",
    "    print('* did map to getSetOfWords function with docs. WITH async')\n",
    "    pool.close()\n",
    "    print('* closed pool')\n",
    "    pool.join()\n",
    "    print('* joined pool')\n",
    "    list_of_sets = [r for r in results0.get() if r is not None] # A BUNCH OF SETS\n",
    "    print(len(list_of_sets))\n",
    "    #print(list_of_sets)\n",
    "    \n",
    "    #init a set\n",
    "    giga_set = set()\n",
    "    #now add all of the sets to it to create one super big set\n",
    "    quick_and_dirty = [giga_set.update(s) for s in list_of_sets]\n",
    "    print(len(giga_set))\n",
    "    print(giga_set)\n",
    "    \n",
    "    #we also need to add these AllenNLP specific things\n",
    "    allen_specific = set(['<S>','</S>','<UNK>'])\n",
    "    giga_set.update(allen_specific)\n",
    "\n",
    "    #now output to vocab.txt\n",
    "    with open(\"mimic_vocab.txt\", \"w\") as out:\n",
    "        for word in giga_set:\n",
    "            out.write(word)\n",
    "            out.write(\"\\n\")\n",
    "    \n",
    "    \n",
    "    print(\" * Created mimic_vocab.txt: done in %0.3fs.\" % (time.time() - t1))\n",
    "\n",
    "\n",
    "createVocabFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We also need the create the mimic_data.txt\"\"\"\n",
    "def createData():\n",
    "    with open(\"mimic_data.txt\", \"w\") as out:\n",
    "        for document in list_of_all_docs[0:3]:\n",
    "            out.write(document)\n",
    "            out.write(\"\\n\")\n",
    "createData()\n",
    "\n",
    "#BOOOO THIS ISN\"T WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
